"""
api_integration.py

M√≥dulo de integraci√≥n que conecta el sistema de clasificaci√≥n inteligente
con la API existente y adapta las b√∫squedas seg√∫n el tipo de consulta.
"""

import time
from typing import Dict, Any, List, Optional
from enum import Enum
from .legal_query_classifier import IntelligentLegalSystem

# Importar el sistema de clasificaci√≥n
from .legal_query_classifier import (
    QueryType, UrgencyLevel, QueryClassification, LegalSpecialist
)
from .llama_integration import EnhancedIntelligentLegalSystem

class EnhancedAPIConsultaHandler:
    """
    Handler mejorado para consultas que integra clasificaci√≥n inteligente
    """
    
    def __init__(self, config: Dict[str, Any], weaviate_client=None, 
                 neo4j_driver=None, documents=None, openai_client=None, llama_config=None):
        self.config = config
        self.weaviate_client = weaviate_client
        self.neo4j_driver = neo4j_driver
        self.documents = documents
        self.openai_client = openai_client
        self.llama_config = llama_config
        
        # Inicializar sistema inteligente
        self.intelligent_system = EnhancedIntelligentLegalSystem(llama_config)
        
        # Mapeo de estrategias de b√∫squeda
        self.search_strategies = {
            "exact_lookup": self._execute_exact_article_search,
            "graph_rag_enhanced": self._execute_enhanced_graph_rag,
            "procedural_chains": self._execute_procedural_search,
            "balanced_comprehensive": self._execute_balanced_search
        }
        
        # Generadores de respuesta especializados
        self.response_generators = {
            "structured_articles": self._generate_article_response,
            "legal_advice": self._generate_legal_advice_response,
            "step_by_step_guide": self._generate_procedural_response,
            "educational_overview": self._generate_educational_response
        }
    
    def process_intelligent_consulta(self, query: str, top_n: int = 15) -> str:
        """
        Procesa una consulta usando el sistema inteligente completo
        """
        print(f"üß† Iniciando procesamiento inteligente para: '{query[:50]}...'")
        start_time = time.time()
        
        try:
            # 1. Clasificar consulta
            classification_result = self.intelligent_system.process_query(query)
            classification = classification_result["classification"]
            specialist_config = classification_result["specialist_routing"]
            
            # 2. Ejecutar b√∫squeda especializada
            search_results = self._execute_specialized_search(
                query, specialist_config, top_n
            )
            
            # 3. Generar respuesta especializada
            response = self._generate_specialized_response(
                query, search_results, classification, specialist_config
            )
            
            processing_time = time.time() - start_time
            print(f"‚úÖ Procesamiento inteligente completado en {processing_time:.2f}s")
            
            return response
            
        except Exception as e:
            print(f"‚ùå Error en procesamiento inteligente: {str(e)}")
            # Fallback a sistema tradicional
            return self._fallback_to_traditional_search(query, top_n)
    
    def _execute_specialized_search(self, query: str, specialist_config: Dict[str, Any], 
                                   top_n: int) -> List[Dict[str, Any]]:
        """Ejecuta b√∫squeda especializada seg√∫n configuraci√≥n del especialista"""
        search_strategy = specialist_config.get("search_strategy", "balanced_comprehensive")
        search_config = specialist_config.get("search_config", {})
        
        # Obtener funci√≥n de b√∫squeda
        search_function = self.search_strategies.get(search_strategy, 
                                                   self._execute_balanced_search)
        
        # Ejecutar b√∫squeda
        return search_function(query, search_config, top_n)
    
    def _execute_exact_article_search(self, query: str, config: Dict[str, Any], 
                                     top_n: int) -> List[Dict[str, Any]]:
        """B√∫squeda exacta de art√≠culos espec√≠ficos"""
        print("üîç Ejecutando b√∫squeda exacta de art√≠culos...")
        
        target_articles = config.get("target_articles", [])
        results = []
        
        if not target_articles:
            # Si no hay art√≠culos espec√≠ficos, usar b√∫squeda tradicional
            return self._execute_balanced_search(query, config, top_n)
        
        # Buscar art√≠culos espec√≠ficos mencionados
        for article_ref in target_articles:
            specific_results = self._search_specific_article(article_ref)
            results.extend(specific_results)
        
        # Si queremos art√≠culos relacionados
        if config.get("include_related", False) and results:
            related_results = self._find_related_articles(results, top_n - len(results))
            results.extend(related_results)
        
        return results[:top_n]
    
    def _execute_enhanced_graph_rag(self, query: str, config: Dict[str, Any], 
                                   top_n: int) -> List[Dict[str, Any]]:
        """B√∫squeda Graph RAG mejorada para an√°lisis de casos"""
        print("üï∏Ô∏è Ejecutando Graph RAG mejorado para an√°lisis de caso...")
        
        # Usar el sistema Graph RAG existente con configuraci√≥n especializada
        if self.neo4j_driver:
            try:
                from .neo4j_utils import search_neo4j_enhanced
                
                # Configurar l√≠mites m√°s altos para casos complejos
                case_elements = config.get("case_elements", {})
                urgency_boost = config.get("urgency_boost", "medium")
                
                # Ajustar l√≠mite seg√∫n urgencia
                if urgency_boost == "high":
                    effective_limit = min(top_n * 2, 25)
                elif urgency_boost == "critical":
                    effective_limit = min(top_n * 3, 30)
                else:
                    effective_limit = top_n
                
                results = search_neo4j_enhanced(self.neo4j_driver, query, effective_limit)
                
                # Aplicar boost contextual para casos
                for result in results:
                    result = self._apply_case_contextual_boost(result, case_elements)
                
                # Re-ordenar por relevancia contextual
                results.sort(key=lambda x: x.get('score', 0), reverse=True)
                
                return results[:top_n]
                
            except Exception as e:
                print(f"‚ùå Error en Graph RAG mejorado: {str(e)}")
        
        # Fallback a b√∫squeda balanceada
        return self._execute_balanced_search(query, config, top_n)
    
    def _execute_procedural_search(self, query: str, config: Dict[str, Any], 
                                  top_n: int) -> List[Dict[str, Any]]:
        """B√∫squeda enfocada en procedimientos y pasos"""
        print("üìã Ejecutando b√∫squeda procedimental...")
        
        # T√©rminos procedimentales espec√≠ficos
        procedural_terms = [
            "procedimiento", "paso", "requisito", "plazo", "formulario",
            "denuncia", "presentar", "tramitar", "solicitar"
        ]
        
        # Modificar consulta para enfocarse en procedimientos
        enhanced_query = f"{query} {' '.join(procedural_terms[:3])}"
        
        # Ejecutar b√∫squeda con t√©rminos procedimentales
        results = self._execute_balanced_search(enhanced_query, config, top_n)
        
        # Filtrar y priorizar art√≠culos procedimentales
        procedural_results = []
        for result in results:
            content_lower = result.get('content', '').lower()
            procedural_score = sum(1 for term in procedural_terms if term in content_lower)
            
            if procedural_score > 0:
                result['procedural_score'] = procedural_score
                result['score'] = result.get('score', 0) + (procedural_score * 0.5)
                procedural_results.append(result)
        
        # Ordenar por relevancia procedimental
        procedural_results.sort(key=lambda x: x.get('procedural_score', 0), reverse=True)
        
        return procedural_results[:top_n]
    
    def _execute_balanced_search(self, query: str, config: Dict[str, Any], 
                                top_n: int) -> List[Dict[str, Any]]:
        """B√∫squeda balanceada tradicional (fallback)"""
        print("‚öñÔ∏è Ejecutando b√∫squeda balanceada...")
        
        try:
            # Usar el sistema existente
            from main import search_query_neutral
            return search_query_neutral(
                query, self.config, self.weaviate_client, 
                self.neo4j_driver, self.documents
            )[:top_n]
        except Exception as e:
            print(f"‚ùå Error en b√∫squeda balanceada: {str(e)}")
            return []
    
    def _search_specific_article(self, article_ref: str) -> List[Dict[str, Any]]:
        """Busca un art√≠culo espec√≠fico por referencia"""
        results = []
        
        # Buscar en Neo4j si est√° disponible
        if self.neo4j_driver:
            try:
                with self.neo4j_driver.session() as session:
                    # Consulta espec√≠fica para art√≠culo
                    query = """
                    MATCH (a:Article)
                    WHERE toLower(a.content) CONTAINS toLower($article_ref)
                    OR a.article_number CONTAINS $article_ref
                    OR a.article_id CONTAINS $article_ref
                    RETURN a.article_id as article_id,
                           a.content as content,
                           a.law_name as law_name,
                           a.article_number as article_number,
                           a.category as category,
                           a.source as source,
                           5.0 as score
                    LIMIT 3
                    """
                    
                    result = session.run(query, article_ref=article_ref)
                    for record in result:
                        results.append({
                            'article_id': record['article_id'],
                            'content': record['content'],
                            'law_name': record['law_name'],
                            'article_number': record['article_number'],
                            'category': record['category'],
                            'source': record['source'],
                            'score': float(record['score']),
                            'method': 'exact_article_lookup'
                        })
            except Exception as e:
                print(f"Error buscando art√≠culo espec√≠fico: {str(e)}")
        
        return results
    
    def _find_related_articles(self, base_articles: List[Dict[str, Any]], 
                              limit: int) -> List[Dict[str, Any]]:
        """Encuentra art√≠culos relacionados a los art√≠culos base"""
        if not base_articles or not self.neo4j_driver:
            return []
        
        related_articles = []
        base_ids = [art['article_id'] for art in base_articles if art.get('article_id')]
        
        if not base_ids:
            return []
        
        try:
            with self.neo4j_driver.session() as session:
                query = """
                MATCH (base:Article)-[r]-(related:Article)
                WHERE base.article_id IN $base_ids
                AND NOT related.article_id IN $base_ids
                
                WITH related, 
                     CASE type(r)
                        WHEN 'SHARES_TAG' THEN 2.0
                        WHEN 'REFERENCES' THEN 3.0
                        WHEN 'SAME_SECTION' THEN 1.5
                        ELSE 1.0
                     END as relation_strength
                
                RETURN DISTINCT related.article_id as article_id,
                       related.content as content,
                       related.law_name as law_name,
                       related.article_number as article_number,
                       related.category as category,
                       related.source as source,
                       max(relation_strength) as score
                
                ORDER BY score DESC
                LIMIT $limit
                """
                
                result = session.run(query, base_ids=base_ids, limit=limit)
                for record in result:
                    related_articles.append({
                        'article_id': record['article_id'],
                        'content': record['content'],
                        'law_name': record['law_name'],
                        'article_number': record['article_number'],
                        'category': record['category'],
                        'source': record['source'],
                        'score': float(record['score']),
                        'method': 'related_to_exact'
                    })
        except Exception as e:
            print(f"Error buscando art√≠culos relacionados: {str(e)}")
        
        return related_articles
    
    def _apply_case_contextual_boost(self, result: Dict[str, Any], 
                                   case_elements: Dict[str, Any]) -> Dict[str, Any]:
        """Aplica boost contextual para an√°lisis de casos"""
        content_lower = result.get('content', '').lower()
        base_score = result.get('score', 0)
        boost_factor = 1.0
        
        # Boost por problemas legales identificados
        legal_issues = case_elements.get('legal_issues', [])
        for issue in legal_issues:
            if issue.replace('_', ' ') in content_lower:
                boost_factor *= 1.3
        
        # Boost por stakeholders relevantes
        stakeholders = case_elements.get('stakeholders', [])
        for stakeholder in stakeholders:
            if stakeholder in content_lower:
                boost_factor *= 1.2
        
        # Boost por da√±os identificados
        damages = case_elements.get('damages_claimed', [])
        for damage in damages:
            if damage in content_lower:
                boost_factor *= 1.25
        
        result['score'] = base_score * boost_factor
        result['case_boost_factor'] = boost_factor
        
        return result
    
    def _generate_specialized_response(self, query: str, search_results: List[Dict[str, Any]], 
                                     classification: Dict[str, Any], 
                                     specialist_config: Dict[str, Any]) -> str:
        """Genera respuesta especializada seg√∫n el tipo de consulta"""
        response_format = specialist_config.get("response_format", "educational_overview")
        
        # Obtener generador de respuesta apropiado
        response_generator = self.response_generators.get(response_format, 
                                                        self._generate_educational_response)
        
        return response_generator(query, search_results, classification, specialist_config)
    
    def _generate_article_response(self, query: str, search_results: List[Dict[str, Any]], 
                                 classification: Dict[str, Any], 
                                 specialist_config: Dict[str, Any]) -> str:
        """Genera respuesta estructurada para consultas de art√≠culos espec√≠ficos"""
        if not search_results:
            return "No se encontraron los art√≠culos espec√≠ficos solicitados. Por favor, verifique la referencia e intente nuevamente."
        
        response_parts = []
        
        # Encabezado espec√≠fico para art√≠culos
        response_parts.append("üìã ART√çCULOS SOLICITADOS\n")
        
        for i, result in enumerate(search_results[:5], 1):
            law_name = result.get('law_name', 'Ley no especificada')
            article_num = result.get('article_number', 'N/A')
            content = result.get('content', 'Contenido no disponible')
            
            response_parts.append(f"**ART√çCULO {i}**")
            response_parts.append(f"üìö Fuente: {law_name}")
            response_parts.append(f"üìÑ Art√≠culo: {article_num}")
            response_parts.append(f"üìù Contenido:\n{content}")
            response_parts.append("-" * 50)
        
        # Agregar explicaci√≥n contextual si hay OpenAI
        if self.openai_client and len(search_results) > 0:
            contextual_explanation = self._generate_contextual_explanation(
                query, search_results[:3], "article_explanation"
            )
            if contextual_explanation:
                response_parts.append("\nüí° EXPLICACI√ìN CONTEXTUAL:")
                response_parts.append(contextual_explanation)
        
        return "\n\n".join(response_parts)
    
    def _generate_legal_advice_response(self, query: str, search_results: List[Dict[str, Any]], 
                                      classification: Dict[str, Any], 
                                      specialist_config: Dict[str, Any]) -> str:
        """Genera respuesta de asesoramiento legal para an√°lisis de casos"""
        if not self.openai_client:
            return "El servicio de asesoramiento legal no est√° disponible en este momento."
        
        try:
            # Preparar contexto especializado para casos
            urgency_level = classification.get("urgency_level", "medium")
            legal_domains = classification.get("legal_domains", [])
            
            # Obtener elementos del caso si est√°n disponibles
            case_analysis = specialist_config.get("case_analysis", {})
            
            # Generar asesoramiento especializado
            legal_advice = self._generate_case_analysis_advice(
                query, search_results, urgency_level, legal_domains, case_analysis
            )
            
            return legal_advice
            
        except Exception as e:
            print(f"Error generando asesoramiento legal: {str(e)}")
            return f"Lo siento, hubo un error al generar el asesoramiento legal. Por favor, consulte con un abogado especializado."
    
    def _generate_procedural_response(self, query: str, search_results: List[Dict[str, Any]], 
                                    classification: Dict[str, Any], 
                                    specialist_config: Dict[str, Any]) -> str:
        """Genera respuesta paso a paso para orientaci√≥n procedimental"""
        if not search_results:
            return "No se encontraron procedimientos espec√≠ficos para su consulta. Le recomiendo consultar con un abogado especializado."
        
        # Generar gu√≠a procedimental estructurada
        if self.openai_client:
            return self._generate_procedural_guide(query, search_results)
        else:
            # Respuesta b√°sica sin OpenAI
            response_parts = ["üìã ORIENTACI√ìN PROCEDIMENTAL\n"]
            
            for i, result in enumerate(search_results[:8], 1):
                content = result.get('content', '')[:300]
                law_name = result.get('law_name', 'N/A')
                article_num = result.get('article_number', 'N/A')
                
                response_parts.append(f"**PASO {i}**")
                response_parts.append(f"üìö Referencia: {law_name} Art. {article_num}")
                response_parts.append(f"üìù Informaci√≥n: {content}...")
                response_parts.append("")
            
            return "\n".join(response_parts)
    
    def _generate_educational_response(self, query: str, search_results: List[Dict[str, Any]], 
                                     classification: Dict[str, Any], 
                                     specialist_config: Dict[str, Any]) -> str:
        """Genera respuesta educativa para consultas generales"""
        if not search_results:
            return "No se encontraron resultados relevantes para su consulta. Por favor, intente reformular su pregunta."
        
        if self.openai_client:
            return self._generate_educational_overview(query, search_results)
        else:
            # Respuesta b√°sica sin OpenAI
            response_parts = ["üìö INFORMACI√ìN LEGAL RELEVANTE\n"]
            
            for i, result in enumerate(search_results[:10], 1):
                law_name = result.get('law_name', 'N/A')
                article_num = result.get('article_number', 'N/A')
                content = result.get('content', '')[:400]
                
                response_parts.append(f"**INFORMACI√ìN {i}**")
                response_parts.append(f"üìö Fuente: {law_name} Art. {article_num}")
                response_parts.append(f"üìù Contenido: {content}...")
                response_parts.append("")
            
            return "\n".join(response_parts)
    
    def _generate_case_analysis_advice(self, query: str, search_results: List[Dict[str, Any]], 
                                     urgency_level: str, legal_domains: List[str], 
                                     case_analysis: Dict[str, Any]) -> str:
        """Genera asesoramiento especializado para an√°lisis de casos"""
        # Preparar contexto espec√≠fico para casos
        relevant_articles_text = ""
        top_articles = search_results[:8]
        
        for i, article in enumerate(top_articles, 1):
            law_name = article.get('law_name', 'Ley no especificada')
            article_num = article.get('article_number', 'N/A')
            content = article.get('content', '')[:600]
            
            relevant_articles_text += f"\n--- Art√≠culo {i} ({law_name} - Art. {article_num}) ---\n{content}\n"
        
        # Prompt especializado para an√°lisis de casos
        system_prompt = f"""Eres un abogado especialista en derecho argentino experto en an√°lisis de casos legales. El usuario presenta una situaci√≥n legal espec√≠fica que requiere asesoramiento pr√°ctico y accionable.

CONTEXTO DEL CASO:
- Urgencia: {urgency_level}
- Dominios legales: {', '.join(legal_domains)}
- Elementos del caso detectados: {case_analysis}

INSTRUCCIONES ESPEC√çFICAS:
1. Analiza la situaci√≥n legal del usuario con profundidad
2. Identifica claramente qu√© derechos le asisten seg√∫n los art√≠culos
3. Eval√∫a las posibles violaciones legales
4. Proporciona recomendaciones espec√≠ficas y PASOS CONCRETOS a seguir
5. Incluye informaci√≥n sobre plazos legales cr√≠ticos
6. Considera el contexto emocional y urgencia de la situaci√≥n
7. Proporciona informaci√≥n sobre recursos disponibles

FORMATO DE RESPUESTA:
üîç **AN√ÅLISIS DE LA SITUACI√ìN**
[An√°lisis detallado de la situaci√≥n legal]

‚öñÔ∏è **DERECHOS QUE LE ASISTEN**
[Derechos espec√≠ficos con base legal]

üö® **VIOLACIONES IDENTIFICADAS** (si aplica)
[Violaciones legales detectadas]

üìã **RECOMENDACIONES ESPEC√çFICAS**
[Acciones concretas a tomar]

‚è∞ **PLAZOS IMPORTANTES**
[Plazos legales cr√≠ticos]

üÜò **PR√ìXIMOS PASOS INMEDIATOS**
[Pasos espec√≠ficos ordenados por prioridad]

‚ö†Ô∏è **ADVERTENCIAS LEGALES**
[Advertencias sobre plazos y riesgos]

üìû **RECURSOS ADICIONALES**
[Informaci√≥n sobre d√≥nde obtener m√°s ayuda]

üîí **DISCLAIMER LEGAL**
[Disclaimer apropiado]"""

        user_prompt = f"""SITUACI√ìN LEGAL: "{query}"

ART√çCULOS LEGALES APLICABLES:
{relevant_articles_text}

Por favor, proporciona un an√°lisis legal completo y asesoramiento pr√°ctico bas√°ndote exclusivamente en estos art√≠culos y tu conocimiento del derecho argentino."""

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=1500,
                temperature=0.2,
                timeout=30.0
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"Error generando an√°lisis de caso: {str(e)}")
            return f"Lo siento, hubo un error al generar el an√°lisis del caso. Error t√©cnico: {str(e)}. Por favor, consulte con un abogado especializado para obtener asesoramiento espec√≠fico sobre su situaci√≥n."
    
    def _generate_procedural_guide(self, query: str, search_results: List[Dict[str, Any]]) -> str:
        """Genera gu√≠a procedimental paso a paso"""
        relevant_articles_text = ""
        for i, article in enumerate(search_results[:6], 1):
            law_name = article.get('law_name', 'Ley no especificada')
            article_num = article.get('article_number', 'N/A')
            content = article.get('content', '')[:500]
            
            relevant_articles_text += f"\n--- Referencia {i} ({law_name} - Art. {article_num}) ---\n{content}\n"
        
        system_prompt = """Eres un experto en procedimientos legales argentinos. Tu tarea es proporcionar una gu√≠a paso a paso clara y pr√°ctica sobre el procedimiento legal consultado.

INSTRUCCIONES:
1. Proporciona una gu√≠a paso a paso detallada
2. Incluye requisitos espec√≠ficos para cada paso
3. Menciona formularios necesarios y d√≥nde obtenerlos
4. Especifica plazos legales importantes
5. Incluye costos aproximados si son relevantes
6. Proporciona alternativas cuando sea posible

FORMATO DE RESPUESTA:
üìã **GU√çA PROCEDIMENTAL PASO A PASO**

üéØ **OBJETIVO**
[Descripci√≥n clara del objetivo del procedimiento]

üìù **PASOS A SEGUIR**

**PASO 1: [T√≠tulo del paso]**
- Descripci√≥n detallada
- Requisitos espec√≠ficos
- Documentos necesarios
- Plazo: [si aplica]
- Costo: [si aplica]

**PASO 2: [T√≠tulo del paso]**
[Continuar con formato similar]

üìã **DOCUMENTOS NECESARIOS**
[Lista completa de documentos requeridos]

üí∞ **COSTOS ESTIMADOS**
[Desglose de costos si aplica]

‚è∞ **PLAZOS IMPORTANTES**
[Plazos cr√≠ticos a tener en cuenta]

üîÑ **ALTERNATIVAS DISPONIBLES**
[Opciones alternativas si existen]

‚ö†Ô∏è **ADVERTENCIAS IMPORTANTES**
[Advertencias sobre el proceso]

üìû **CONTACTOS √öTILES**
[Informaci√≥n de contacto relevante]"""

        user_prompt = f"""CONSULTA PROCEDIMENTAL: "{query}"

REFERENCIAS LEGALES:
{relevant_articles_text}

Por favor, proporciona una gu√≠a procedimental completa y pr√°ctica."""

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=1200,
                temperature=0.1,
                timeout=30.0
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"Error generando gu√≠a procedimental: {str(e)}")
            return f"Lo siento, hubo un error al generar la gu√≠a procedimental. Por favor, consulte con un abogado especializado."
    
    def _generate_educational_overview(self, query: str, search_results: List[Dict[str, Any]]) -> str:
        """Genera overview educativo para consultas generales"""
        relevant_articles_text = ""
        for i, article in enumerate(search_results[:8], 1):
            law_name = article.get('law_name', 'Ley no especificada')
            article_num = article.get('article_number', 'N/A')
            content = article.get('content', '')[:400]
            
            relevant_articles_text += f"\n--- Art√≠culo {i} ({law_name} - Art. {article_num}) ---\n{content}\n"
        
        system_prompt = """Eres un experto en derecho argentino que proporciona informaci√≥n educativa clara y accesible. Tu objetivo es educar al usuario sobre el tema legal consultado.

INSTRUCCIONES:
1. Proporciona una explicaci√≥n clara y educativa
2. Usa un lenguaje accesible evitando jerga legal excesiva
3. Incluye ejemplos pr√°cticos cuando sea relevante
4. Menciona los aspectos m√°s importantes del tema
5. Proporciona una base s√≥lida para entender el tema

FORMATO DE RESPUESTA:
üìö **INFORMACI√ìN EDUCATIVA**

üéØ **RESUMEN EJECUTIVO**
[Resumen claro del tema consultado]

üìñ **CONCEPTOS FUNDAMENTALES**
[Explicaci√≥n de conceptos clave]

‚öñÔ∏è **MARCO LEGAL**
[Base legal del tema con art√≠culos relevantes]

üí° **EJEMPLOS PR√ÅCTICOS**
[Ejemplos que ilustren los conceptos]

üîç **ASPECTOS IMPORTANTES**
[Puntos clave a tener en cuenta]

üìã **PR√ìXIMOS PASOS SUGERIDOS**
[Qu√© hacer si el usuario necesita m√°s informaci√≥n]

üìö **RECURSOS ADICIONALES**
[Referencias para profundizar en el tema]"""

        user_prompt = f"""CONSULTA EDUCATIVA: "{query}"

ART√çCULOS LEGALES RELEVANTES:
{relevant_articles_text}

Por favor, proporciona una explicaci√≥n educativa completa sobre este tema legal."""

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=1200,
                temperature=0.3,
                timeout=30.0
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"Error generando overview educativo: {str(e)}")
            return f"Lo siento, hubo un error al generar la informaci√≥n educativa. Por favor, consulte con un abogado especializado."
    
    def _generate_contextual_explanation(self, query: str, search_results: List[Dict[str, Any]], 
                                       explanation_type: str) -> Optional[str]:
        """Genera explicaci√≥n contextual espec√≠fica"""
        if not self.openai_client or not search_results:
            return None
        
        try:
            context_text = ""
            for result in search_results:
                context_text += f"{result.get('content', '')[:300]}...\n\n"
            
            explanation_prompt = f"""Proporciona una explicaci√≥n breve y clara sobre estos art√≠culos legales en relaci√≥n a la consulta: "{query}"

Art√≠culos:
{context_text}

Explicaci√≥n (m√°ximo 200 palabras):"""

            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "user", "content": explanation_prompt}
                ],
                max_tokens=300,
                temperature=0.2,
                timeout=15.0
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"Error generando explicaci√≥n contextual: {str(e)}")
            return None
    
    def _fallback_to_traditional_search(self, query: str, top_n: int) -> str:
        """Fallback al sistema tradicional cuando el inteligente falla"""
        print("üîÑ Fallback a sistema tradicional...")
        
        try:
            from main import search_query_neutral
            
            # Usar b√∫squeda tradicional
            search_results = search_query_neutral(
                query, self.config, self.weaviate_client, 
                self.neo4j_driver, self.documents
            )[:top_n]
            
            # Generar respuesta tradicional con GPT si est√° disponible
            if self.openai_client and search_results:
                return self._generate_traditional_gpt_response(query, search_results)
            else:
                return "Lo siento, el sistema no est√° disponible en este momento. Por favor, consulte con un abogado especializado."
                
        except Exception as e:
            print(f"Error en fallback tradicional: {str(e)}")
            return "Lo siento, ocurri√≥ un error al procesar su consulta. Por favor, intente nuevamente o consulte con un abogado especializado."
    
    def _generate_traditional_gpt_response(self, query: str, search_results: List[Dict[str, Any]]) -> str:
        """Genera respuesta usando el sistema GPT tradicional"""
        try:
            # Usar el generador GPT existente del sistema
            from api import generate_gpt_advice
            return generate_gpt_advice(query, search_results)
        except Exception as e:
            print(f"Error en respuesta GPT tradicional: {str(e)}")
            return f"Lo siento, hubo un error al generar la respuesta. Error: {str(e)}"


# ========== INTEGRACI√ìN CON LA API EXISTENTE ==========

def integrate_intelligent_system_with_api():
    """
    Funci√≥n para integrar el sistema inteligente con la API existente
    """
    print("üöÄ Integrando sistema inteligente con API existente...")
    
    # Modificaciones necesarias en api.py:
    
    integration_code = '''
# Agregar al inicio de api.py despu√©s de las importaciones existentes:
from .api_integration import EnhancedAPIConsultaHandler

# Modificar la funci√≥n startup_event() para incluir el handler inteligente:
enhanced_handler = None

@app.on_event("startup")
async def startup_event():
    """Inicializar conexiones y cargar configuraci√≥n al iniciar la API."""
    global config, weaviate_client, neo4j_driver, documents, openai_client, enhanced_handler
    
    # ... c√≥digo existente ...
    
    # Inicializar handler inteligente
    enhanced_handler = EnhancedAPIConsultaHandler(
        config=config,
        weaviate_client=weaviate_client,
        neo4j_driver=neo4j_driver,
        documents=documents,
        openai_client=openai_client
    )
    
    print("üß† Sistema inteligente de clasificaci√≥n inicializado")

# Modificar el endpoint /consulta para usar el sistema inteligente:
@app.post("/consulta", response_model=ConsultaResponse)
async def realizar_consulta(request: ConsultaRequest):
    """
    Realizar una consulta legal con clasificaci√≥n inteligente y asesoramiento especializado.
    """
    start_time = time.time()
    
    try:
        # Validaciones existentes...
        if not documents:
            return ConsultaResponse(
                response="Lo siento, el sistema no est√° disponible en este momento."
            )
        
        if not openai_client:
            return ConsultaResponse(
                response="Lo siento, el servicio de asesoramiento legal no est√° disponible."
            )
        
        print(f"üß† Procesando consulta inteligente: '{request.query}'")
        
        # Usar el sistema inteligente
        intelligent_response = enhanced_handler.process_intelligent_consulta(
            request.query, request.top_n
        )
        
        execution_time = time.time() - start_time
        print(f"‚úÖ Consulta inteligente procesada en {execution_time:.2f}s")
        
        return ConsultaResponse(response=intelligent_response)
        
    except Exception as e:
        print(f"‚ùå Error en consulta inteligente: {str(e)}")
        return ConsultaResponse(
            response=f"Lo siento, ocurri√≥ un error al procesar su consulta: {str(e)}"
        )

# Agregar endpoint para informaci√≥n del sistema inteligente:
@app.get("/sistema/info")
async def obtener_info_sistema():
    """Obtener informaci√≥n sobre el sistema de clasificaci√≥n inteligente."""
    return {
        "sistema": "Clasificaci√≥n Inteligente de Consultas Legales",
        "version": "1.0.0",
        "tipos_consulta": [
            {"tipo": "article_lookup", "descripcion": "B√∫squeda espec√≠fica de art√≠culos"},
            {"tipo": "case_analysis", "descripcion": "An√°lisis de situaci√≥n legal espec√≠fica"},
            {"tipo": "general_consultation", "descripcion": "Consulta general sobre derecho"},
            {"tipo": "procedural_guidance", "descripcion": "Orientaci√≥n sobre procedimientos"},
            {"tipo": "comparative_analysis", "descripcion": "Comparaci√≥n entre leyes/art√≠culos"}
        ],
        "especialistas": [
            {"especialista": "article_specialist", "descripcion": "Especialista en b√∫squeda de art√≠culos"},
            {"especialista": "case_analyst", "descripcion": "Analista de casos legales"},
            {"especialista": "procedural_guide", "descripcion": "Gu√≠a procedimental"},
            {"especialista": "general_counselor", "descripcion": "Consejero general"}
        ],
        "caracteristicas": [
            "Clasificaci√≥n autom√°tica con Llama",
            "Routing a especialistas apropiados", 
            "An√°lisis contextual avanzado",
            "Respuestas adaptadas al tipo de consulta",
            "Detecci√≥n de urgencia y contexto emocional"
        ]
    }

# Agregar endpoint para testing de clasificaci√≥n:
@app.post("/sistema/clasificar")
async def clasificar_consulta(request: dict):
    """Endpoint para testing de clasificaci√≥n de consultas."""
    try:
        query = request.get("query", "")
        if not query:
            return {"error": "Query requerido"}
        
        # Usar solo el clasificador
        classification_result = enhanced_handler.intelligent_system.process_query(query)
        
        return {
            "query": query,
            "clasificacion": classification_result["classification"],
            "especialista_recomendado": classification_result["specialist_routing"]["specialist_type"],
            "estrategia_busqueda": classification_result["specialist_routing"]["search_strategy"]
        }
    except Exception as e:
        return {"error": f"Error en clasificaci√≥n: {str(e)}"}
'''
    
    print("üìã C√≥digo de integraci√≥n generado.")
    print("üîß Para completar la integraci√≥n:")
    print("   1. Agregar EnhancedAPIConsultaHandler a api.py")
    print("   2. Modificar startup_event() para inicializar el handler")
    print("   3. Actualizar endpoint /consulta para usar el sistema inteligente")
    print("   4. Agregar endpoints adicionales para informaci√≥n del sistema")
    
    return integration_code


# ========== EJEMPLO DE USO COMPLETO ==========

def demo_complete_integration():
    """Demostraci√≥n completa del sistema integrado"""
    print("="*80)
    print("üöÄ DEMOSTRACI√ìN COMPLETA - SISTEMA INTELIGENTE INTEGRADO")
    print("="*80)
    
    # Simular configuraci√≥n
    mock_config = {
        "weaviate": {"enabled": True},
        "neo4j": {"enabled": True},
        "retrieval": {"top_n": 15}
    }
    
    # Crear handler (sin clientes reales para demo)
    handler = EnhancedAPIConsultaHandler(
        config=mock_config,
        weaviate_client=None,  # En producci√≥n ser√≠an clientes reales
        neo4j_driver=None,
        documents=None,
        openai_client=None
    )
    
    # Casos de prueba que demuestran diferentes tipos de consultas
    test_cases = [
        {
            "query": "¬øCu√°l es el art√≠culo 14 del c√≥digo penal?",
            "expected_type": "article_lookup",
            "expected_specialist": "article_specialist"
        },
        {
            "query": "Fui despedida luego de trabajar durante 5 a√±os sin indemnizaci√≥n despu√©s de avisar que estoy embarazada",
            "expected_type": "case_analysis", 
            "expected_specialist": "case_analyst"
        },
        {
            "query": "¬øC√≥mo presento una denuncia por acoso laboral en el ministerio de trabajo?",
            "expected_type": "procedural_guidance",
            "expected_specialist": "procedural_guide"
        },
        {
            "query": "¬øCu√°les son mis derechos como trabajador en Argentina?",
            "expected_type": "general_consultation",
            "expected_specialist": "general_counselor"
        },
        {
            "query": "¬øQu√© diferencias hay entre despido con causa justificada y sin causa?",
            "expected_type": "comparative_analysis",
            "expected_specialist": "general_counselor"
        }
    ]
    
    print(f"\nüß™ Probando {len(test_cases)} casos de diferentes tipos de consultas...\n")
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"{'='*60}")
        print(f"CASO DE PRUEBA {i}")
        print(f"{'='*60}")
        print(f"üìù Consulta: {test_case['query']}")
        print(f"üéØ Tipo esperado: {test_case['expected_type']}")
        print(f"üë®‚Äç‚öñÔ∏è Especialista esperado: {test_case['expected_specialist']}")
        
        # Procesar con sistema inteligente
        try:
            result = handler.intelligent_system.process_query(test_case['query'])
            
            classification = result["classification"]
            specialist_config = result["specialist_routing"]
            
            print(f"\n‚úÖ RESULTADO:")
            print(f"   üè∑Ô∏è  Tipo detectado: {classification['query_type']}")
            print(f"   üë®‚Äç‚öñÔ∏è Especialista asignado: {specialist_config['specialist_type']}")
            print(f"   üîç Estrategia de b√∫squeda: {specialist_config['search_strategy']}")
            print(f"   üìä Confianza: {classification['confidence']:.2f}")
            print(f"   üìà Dominios: {', '.join(classification['legal_domains'])}")
            
            # Verificar predicci√≥n
            type_correct = classification['query_type'] == test_case['expected_type']
            specialist_correct = specialist_config['specialist_type'] == test_case['expected_specialist']
            
            print(f"\nüéØ PRECISI√ìN:")
            print(f"   ‚úÖ Tipo: {'CORRECTO' if type_correct else 'INCORRECTO'}")
            print(f"   ‚úÖ Especialista: {'CORRECTO' if specialist_correct else 'INCORRECTO'}")
            
        except Exception as e:
            print(f"‚ùå ERROR: {str(e)}")
        
        print()
    
    print("="*80)
    print("üìä RESUMEN DE LA DEMOSTRACI√ìN")
    print("="*80)
    print("‚úÖ Sistema de clasificaci√≥n inteligente funcional")
    print("‚úÖ Routing autom√°tico a especialistas apropiados")
    print("‚úÖ Configuraci√≥n de b√∫squeda adaptada por tipo de consulta")
    print("‚úÖ An√°lisis contextual y detecci√≥n de urgencia")
    print("‚úÖ Preparado para integraci√≥n con API existente")
    print("\nüöÄ ¬°Sistema listo para implementaci√≥n!")


if __name__ == "__main__":
    # Ejecutar demostraci√≥n
    demo_complete_integration()
    
    # Mostrar c√≥digo de integraci√≥n
    print("\n" + "="*80)
    print("üîß C√ìDIGO DE INTEGRACI√ìN")
    print("="*80)
    integration_code = integrate_intelligent_system_with_api()
    print(integration_code)