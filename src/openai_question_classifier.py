"""
openai_question_classifier.py

Clasificador de consultas legales usando OpenAI GPT como alternativa a Llama.
Integra perfectamente con el sistema existente y permite desactivar f√°cilmente.
"""

import json
import time
import os
from typing import Dict, Any, List, Optional
from openai import OpenAI

class OpenAIQuestionClassifier:
    """
    Clasificador de consultas legales usando OpenAI GPT
    """
    
    def __init__(self, openai_client: OpenAI, model: str = "gpt-4o-mini"):
        self.client = openai_client
        self.model = model
        self.available = bool(openai_client)
        
        # Prompt optimizado para clasificaci√≥n de 3 categor√≠as
        self.classification_prompt = self._build_classification_prompt()
        
    def _build_classification_prompt(self) -> str:
        """Construye el prompt optimizado para OpenAI"""
        return """Eres un experto jurista argentino especializado en clasificar consultas legales. Tu tarea es analizar la consulta del usuario y clasificarla en UNA de estas 3 categor√≠as EXACTAS:

**TIPOS DE CONSULTA (elegir solo UNO):**

1. **articles_search**: B√∫squeda espec√≠fica de art√≠culos legales o normas
   - Ejemplos: "¬øCu√°l es el art√≠culo 14 del c√≥digo penal?", "Mu√©strame el art√≠culo 75 de la LCT", "Art√≠culo sobre despidos"
   - Palabras clave: "art√≠culo", "art.", "c√≥digo", "ley", n√∫mero espec√≠fico

2. **case_analysis**: An√°lisis de una situaci√≥n legal espec√≠fica del usuario (caso personal)
   - Ejemplos: "Fui despedido sin indemnizaci√≥n", "Mi jefe me discrimina por embarazo", "Me deben salarios"
   - Palabras clave: "fui", "me", "mi jefe", "mi empleador", situaciones personales

3. **legal_advice**: Consulta general sobre temas legales (informaci√≥n educativa)
   - Ejemplos: "¬øCu√°les son mis derechos laborales?", "¬øC√≥mo funciona el divorcio?", "Derechos del trabajador"
   - Palabras clave: "cu√°les son", "c√≥mo", "qu√© es", consultas generales

**INSTRUCCIONES ESTRICTAS:**
1. Debes elegir EXACTAMENTE uno de estos 3 tipos: "articles_search", "case_analysis", "legal_advice"
2. Crea un t√≠tulo descriptivo y espec√≠fico para la conversaci√≥n (m√°ximo 50 caracteres)
3. El t√≠tulo debe reflejar el contenido espec√≠fico de la consulta
4. Responde √öNICAMENTE con el JSON solicitado, sin texto adicional

**FORMATO DE RESPUESTA (JSON √∫nicamente):**
{
    "question_type": "articles_search",
    "dialogue_title": "Art√≠culo 14 C√≥digo Penal"
}

**CONSULTA A CLASIFICAR:**
{query}"""

    def classify_question(self, query: str) -> Dict[str, str]:
        """
        Clasifica la consulta usando OpenAI GPT
        
        Args:
            query: Consulta del usuario
            
        Returns:
            Dict con question_type y dialogue_title
        """
        if not self.available:
            raise Exception("OpenAI client no disponible")
        
        print(f"ü§ñ Clasificando con OpenAI: '{query[:50]}...'")
        start_time = time.time()
        
        try:
            # Llamar a OpenAI
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Eres un clasificador experto de consultas legales. Responde √öNICAMENTE con JSON v√°lido."},
                    {"role": "user", "content": self.classification_prompt.format(query=query)}
                ],
                max_tokens=150,
                temperature=0.1,  # Muy baja para respuestas consistentes
                timeout=15.0
            )
            
            # Extraer respuesta
            classification_text = response.choices[0].message.content.strip()
            
            # Parsear JSON
            classification_data = self._parse_openai_response(classification_text)
            
            # Validar y normalizar
            validated_data = self._validate_classification(classification_data, query)
            
            elapsed_time = time.time() - start_time
            print(f"‚úÖ Clasificaci√≥n OpenAI completada en {elapsed_time:.2f}s")
            print(f"   üè∑Ô∏è Tipo: {validated_data['question_type']}")
            print(f"   üìù T√≠tulo: {validated_data['dialogue_title']}")
            
            return validated_data
            
        except Exception as e:
            print(f"‚ùå Error en clasificaci√≥n OpenAI: {str(e)}")
            # Fallback a clasificaci√≥n de reglas
            return self._rule_based_fallback(query)
    
    def _parse_openai_response(self, response_text: str) -> Dict[str, str]:
        """Parsea la respuesta JSON de OpenAI"""
        try:
            # Limpiar respuesta
            response_clean = response_text.strip()
            
            # Buscar JSON en la respuesta
            json_start = response_clean.find('{')
            json_end = response_clean.rfind('}') + 1
            
            if json_start == -1 or json_end == 0:
                raise ValueError("No se encontr√≥ JSON v√°lido en respuesta de OpenAI")
            
            json_str = response_clean[json_start:json_end]
            
            # Parsear JSON
            parsed_data = json.loads(json_str)
            
            return parsed_data
            
        except json.JSONDecodeError as e:
            print(f"‚ùå Error parseando JSON de OpenAI: {str(e)}")
            print(f"Respuesta recibida: {response_text}")
            raise
        except Exception as e:
            print(f"‚ùå Error procesando respuesta de OpenAI: {str(e)}")
            raise
    
    def _validate_classification(self, data: Dict[str, str], original_query: str) -> Dict[str, str]:
        """Valida y normaliza los datos de clasificaci√≥n"""
        
        # Tipos v√°lidos
        valid_types = ["articles_search", "case_analysis", "legal_advice"]
        
        # Validar question_type
        question_type = data.get("question_type", "").lower().strip()
        if question_type not in valid_types:
            print(f"‚ö†Ô∏è Tipo inv√°lido '{question_type}', usando fallback")
            question_type = self._guess_type_from_query(original_query)
        
        # Validar y limpiar dialogue_title
        dialogue_title = data.get("dialogue_title", "").strip()
        if not dialogue_title or len(dialogue_title) < 3:
            dialogue_title = self._generate_title_from_query(original_query, question_type)
        
        # Limitar longitud del t√≠tulo
        if len(dialogue_title) > 50:
            dialogue_title = dialogue_title[:47] + "..."
        
        return {
            "question_type": question_type,
            "dialogue_title": dialogue_title
        }
    
    def _guess_type_from_query(self, query: str) -> str:
        """Adivina el tipo basado en patrones en la consulta"""
        query_lower = query.lower()
        
        # Buscar art√≠culos espec√≠ficos
        if any(pattern in query_lower for pattern in ['art√≠culo', 'art.', 'art ', 'c√≥digo']):
            return "articles_search"
        
        # Buscar situaciones personales
        if any(pattern in query_lower for pattern in ['fui', 'me ', 'mi jefe', 'mi empleador', 'despidieron', 'discriminan']):
            return "case_analysis"
        
        # Por defecto, consulta general
        return "legal_advice"
    
    def _generate_title_from_query(self, query: str, question_type: str) -> str:
        """Genera un t√≠tulo basado en la consulta y el tipo"""
        query_words = query.split()[:6]  # Primeras 6 palabras
        base_title = " ".join(query_words)
        
        # Prefijos por tipo
        prefixes = {
            "articles_search": "B√∫squeda: ",
            "case_analysis": "Caso: ",
            "legal_advice": "Consulta: "
        }
        
        prefix = prefixes.get(question_type, "")
        title = f"{prefix}{base_title}"
        
        return title[:50]
    
    def _rule_based_fallback(self, query: str) -> Dict[str, str]:
        """Clasificaci√≥n de fallback cuando OpenAI falla"""
        print("üîÑ Usando clasificaci√≥n de reglas como fallback...")
        
        question_type = self._guess_type_from_query(query)
        dialogue_title = self._generate_title_from_query(query, question_type)
        
        return {
            "question_type": question_type,
            "dialogue_title": dialogue_title
        }


class EnhancedLegalSystemWithOpenAI:
    """
    Sistema legal mejorado que puede usar OpenAI o Llama seg√∫n disponibilidad
    """
    
    def __init__(self, config: Dict[str, Any], openai_client: Optional[OpenAI] = None):
        self.config = config
        self.openai_client = openai_client
        
        # Flags de configuraci√≥n
        self.use_openai_classifier = config.get("use_openai_classifier", True)  # Por defecto usar OpenAI
        self.use_llama_fallback = config.get("use_llama_fallback", True)       # Llama como fallback
        
        # Inicializar clasificadores
        self.openai_classifier = None
        self.llama_system = None
        
        # Configurar OpenAI classifier
        if self.use_openai_classifier and openai_client:
            try:
                self.openai_classifier = OpenAIQuestionClassifier(
                    openai_client=openai_client,
                    model=config.get("openai_model", "gpt-4o-mini")
                )
                print("ü§ñ OpenAI classifier inicializado correctamente")
            except Exception as e:
                print(f"‚ùå Error inicializando OpenAI classifier: {str(e)}")
        
        # Configurar Llama fallback
        if self.use_llama_fallback:
            try:
                from .llama_integration import EnhancedIntelligentLegalSystem
                self.llama_system = EnhancedIntelligentLegalSystem(
                    config.get("llama_config", {})
                )
                print("ü¶ô Llama system inicializado como fallback")
            except Exception as e:
                print(f"‚ö†Ô∏è Llama system no disponible: {str(e)}")
    
    def classify_question_smart(self, query: str) -> Dict[str, Any]:
        """
        Clasifica la consulta usando el mejor m√©todo disponible
        
        Returns:
            Dict con question_type, dialogue_title y metadata adicional
        """
        print(f"\nüß† CLASIFICACI√ìN INTELIGENTE: '{query[:50]}...'")
        
        # Intentar con OpenAI primero (si est√° configurado)
        if self.use_openai_classifier and self.openai_classifier:
            try:
                result = self.openai_classifier.classify_question(query)
                
                # Expandir resultado con metadata
                return {
                    "question_type": result["question_type"],
                    "dialogue_title": result["dialogue_title"],
                    "classification_method": "openai",
                    "confidence": 0.9,  # Alta confianza para OpenAI
                    "timestamp": time.time()
                }
                
            except Exception as e:
                print(f"‚ùå Error con OpenAI classifier: {str(e)}")
                print("üîÑ Intentando con fallback...")
        
        # Fallback a Llama (si est√° disponible)
        if self.use_llama_fallback and self.llama_system:
            try:
                llama_result = self.llama_system.process_query_with_real_llama(query)
                
                # Convertir resultado de Llama al formato esperado
                classification = llama_result["classification"]
                
                # Mapear tipos de Llama a los 3 tipos simplificados
                question_type = self._map_llama_type_to_simple(classification["query_type"])
                dialogue_title = self._generate_title_from_llama_result(query, classification)
                
                return {
                    "question_type": question_type,
                    "dialogue_title": dialogue_title,
                    "classification_method": "llama_fallback",
                    "confidence": classification.get("confidence", 0.7),
                    "timestamp": time.time(),
                    "llama_details": classification  # Detalles adicionales de Llama
                }
                
            except Exception as e:
                print(f"‚ùå Error con Llama fallback: {str(e)}")
        
        # √öltimo fallback: clasificaci√≥n de reglas simples
        print("üîÑ Usando clasificaci√≥n de reglas como √∫ltimo recurso...")
        return self._ultimate_fallback_classification(query)
    
    def _map_llama_type_to_simple(self, llama_type: str) -> str:
        """Mapea los tipos de Llama a los 3 tipos simplificados"""
        mapping = {
            "article_lookup": "articles_search",
            "case_analysis": "case_analysis", 
            "general_consultation": "legal_advice",
            "procedural_guidance": "legal_advice",
            "comparative_analysis": "legal_advice"
        }
        
        return mapping.get(llama_type, "legal_advice")
    
    def _generate_title_from_llama_result(self, query: str, classification: Dict[str, Any]) -> str:
        """Genera t√≠tulo basado en resultado de Llama"""
        # Usar dominios legales de Llama para crear un t√≠tulo m√°s espec√≠fico
        domains = classification.get("legal_domains", [])
        query_type = classification.get("query_type", "")
        
        # Crear t√≠tulo basado en el dominio y tipo
        if domains:
            primary_domain = domains[0].capitalize()
            if query_type == "article_lookup":
                title = f"Art√≠culo - {primary_domain}"
            elif query_type == "case_analysis":
                title = f"Caso {primary_domain}"
            else:
                title = f"Consulta {primary_domain}"
        else:
            # Fallback a primeras palabras de la consulta
            words = query.split()[:4]
            title = " ".join(words)
        
        return title[:50]
    
    def _ultimate_fallback_classification(self, query: str) -> Dict[str, Any]:
        """Clasificaci√≥n de √∫ltimo recurso usando reglas simples"""
        query_lower = query.lower()
        
        # Detectar tipo
        if any(pattern in query_lower for pattern in ['art√≠culo', 'art.', 'c√≥digo']):
            question_type = "articles_search"
            title = "B√∫squeda de Art√≠culo"
        elif any(pattern in query_lower for pattern in ['fui', 'me ', 'mi jefe', 'despidieron']):
            question_type = "case_analysis"
            title = "An√°lisis de Caso"
        else:
            question_type = "legal_advice"
            title = "Consulta Legal"
        
        # Mejorar t√≠tulo con palabras de la consulta
        query_words = query.split()[:3]
        if query_words:
            title = f"{title}: {' '.join(query_words)}"
        
        return {
            "question_type": question_type,
            "dialogue_title": title[:50],
            "classification_method": "simple_rules",
            "confidence": 0.5,
            "timestamp": time.time()
        }
    
    def get_classifier_status(self) -> Dict[str, Any]:
        """Obtiene el estado de los clasificadores disponibles"""
        return {
            "openai_available": bool(self.openai_classifier),
            "llama_available": bool(self.llama_system),
            "openai_enabled": self.use_openai_classifier,
            "llama_fallback_enabled": self.use_llama_fallback,
            "active_method": self._get_active_method()
        }
    
    def _get_active_method(self) -> str:
        """Determina cu√°l ser√° el m√©todo activo de clasificaci√≥n"""
        if self.use_openai_classifier and self.openai_classifier:
            return "openai_primary"
        elif self.use_llama_fallback and self.llama_system:
            return "llama_only"
        else:
            return "rules_only"


# ========== INTEGRACI√ìN CON API EXISTENTE ==========

def integrate_openai_classifier_with_api():
    """
    C√≥digo para integrar el clasificador OpenAI con la API existente
    """
    
    integration_code = '''
# ===== MODIFICACIONES EN api.py =====

# 1. Agregar import al inicio del archivo
from .openai_question_classifier import EnhancedLegalSystemWithOpenAI

# 2. Modificar startup_event() para incluir el clasificador OpenAI
enhanced_legal_system = None

@app.on_event("startup") 
async def startup_event():
    """Inicializar conexiones y cargar configuraci√≥n al iniciar la API."""
    global config, weaviate_client, neo4j_driver, documents, openai_client, enhanced_legal_system
    
    # ... tu c√≥digo existente ...
    
    # ===== NUEVO: INICIALIZAR SISTEMA CON OPENAI CLASSIFIER =====
    try:
        # Configuraci√≥n del clasificador
        classifier_config = {
            "use_openai_classifier": True,  # Usar OpenAI como principal
            "use_llama_fallback": True,     # Llama como fallback
            "openai_model": "gpt-4o-mini",  # Modelo a usar
            "llama_config": {
                "ollama_model": "llama2",
                "huggingface_api_key": os.getenv("HUGGINGFACE_API_KEY"),
                "local_model": "microsoft/DialoGPT-medium"
            }
        }
        
        enhanced_legal_system = EnhancedLegalSystemWithOpenAI(
            config=classifier_config,
            openai_client=openai_client
        )
        
        print("ü§ñ Sistema de clasificaci√≥n inteligente inicializado (OpenAI + Llama)")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error inicializando clasificador: {str(e)}")
        enhanced_legal_system = None

# 3. Agregar endpoint para clasificaci√≥n de preguntas
@app.post("/classify")
async def classify_question(request: dict):
    """Clasifica una pregunta en las 3 categor√≠as principales."""
    try:
        query = request.get("query", "")
        if not query:
            return {"error": "Query requerido"}
        
        if not enhanced_legal_system:
            return {"error": "Sistema de clasificaci√≥n no disponible"}
        
        # Clasificar pregunta
        result = enhanced_legal_system.classify_question_smart(query)
        
        return {
            "success": True,
            "result": {
                "question_type": result["question_type"],
                "dialogue_title": result["dialogue_title"]
            },
            "metadata": {
                "classification_method": result["classification_method"],
                "confidence": result["confidence"],
                "timestamp": result["timestamp"]
            }
        }
        
    except Exception as e:
        return {"error": f"Error en clasificaci√≥n: {str(e)}"}

# 4. Agregar endpoint para estado del clasificador
@app.get("/classifier/status")
async def get_classifier_status():
    """Obtiene el estado del sistema de clasificaci√≥n."""
    if not enhanced_legal_system:
        return {"error": "Sistema de clasificaci√≥n no inicializado"}
    
    status = enhanced_legal_system.get_classifier_status()
    
    return {
        "status": status,
        "available_methods": {
            "openai": "Clasificaci√≥n r√°pida y precisa con GPT",
            "llama": "Clasificaci√≥n avanzada con Llama (fallback)",
            "rules": "Clasificaci√≥n b√°sica por reglas (√∫ltimo recurso)"
        }
    }

# 5. Modificar endpoint /consulta para incluir clasificaci√≥n autom√°tica
@app.post("/consulta", response_model=ConsultaResponse)
async def realizar_consulta(request: ConsultaRequest):
    """
    Realizar una consulta legal con clasificaci√≥n autom√°tica de pregunta.
    """
    start_time = time.time()
    
    try:
        # ... validaciones existentes ...
        
        print(f"üß† Procesando consulta: '{request.query}'")
        
        # NUEVO: Clasificar pregunta autom√°ticamente
        classification_result = None
        if enhanced_legal_system:
            try:
                classification_result = enhanced_legal_system.classify_question_smart(request.query)
                print(f"   üìã Clasificada como: {classification_result['question_type']}")
                print(f"   üìù T√≠tulo: {classification_result['dialogue_title']}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Error en clasificaci√≥n: {str(e)}")
        
        # Continuar con la l√≥gica existente de b√∫squeda y respuesta...
        # (tu c√≥digo actual)
        
        # Agregar informaci√≥n de clasificaci√≥n a la respuesta
        if classification_result:
            response_text = f"**{classification_result['dialogue_title']}**\\n\\n{gpt_response}"
        else:
            response_text = gpt_response
        
        execution_time = time.time() - start_time
        print(f"‚úÖ Consulta procesada en {execution_time:.2f}s")
        
        return ConsultaResponse(response=response_text)
        
    except Exception as e:
        print(f"‚ùå Error procesando consulta: {str(e)}")
        return ConsultaResponse(
            response=f"Lo siento, ocurri√≥ un error al procesar su consulta: {str(e)}"
        )
'''
    
    return integration_code


# ========== EJEMPLOS DE USO ==========

def test_openai_classifier():
    """Funci√≥n para probar el clasificador OpenAI"""
    
    # Configuraci√≥n de prueba
    config = {
        "use_openai_classifier": True,
        "use_llama_fallback": False,  # Desactivar Llama para esta prueba
        "openai_model": "gpt-4o-mini"
    }
    
    # Crear cliente OpenAI de prueba (necesitar√°s tu API key)
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    # Inicializar sistema
    system = EnhancedLegalSystemWithOpenAI(config, openai_client)
    
    # Consultas de prueba
    test_queries = [
        "¬øCu√°l es el art√≠culo 14 del c√≥digo penal?",
        "Fui despedida sin indemnizaci√≥n por estar embarazada", 
        "¬øCu√°les son mis derechos como trabajador?",
        "Art√≠culo 75 de la constituci√≥n nacional",
        "Mi jefe me discrimina por mi edad",
        "¬øC√≥mo presento una denuncia laboral?"
    ]
    
    print("üß™ PROBANDO CLASIFICADOR OPENAI")
    print("="*50)
    
    for i, query in enumerate(test_queries, 1):
        print(f"\\n{'='*40}")
        print(f"PRUEBA {i}: {query}")
        print(f"{'='*40}")
        
        try:
            result = system.classify_question_smart(query)
            
            print(f"‚úÖ RESULTADO:")
            print(f"   üè∑Ô∏è Tipo: {result['question_type']}")
            print(f"   üìù T√≠tulo: {result['dialogue_title']}")
            print(f"   üîß M√©todo: {result['classification_method']}")
            print(f"   üìä Confianza: {result['confidence']:.2f}")
            
        except Exception as e:
            print(f"‚ùå ERROR: {str(e)}")


if __name__ == "__main__":
    print("ü§ñ CLASIFICADOR OPENAI PARA CONSULTAS LEGALES")
    print("="*50)
    print("\\nEste m√≥dulo proporciona:")
    print("‚úÖ Clasificaci√≥n en 3 categor√≠as: articles_search, case_analysis, legal_advice")
    print("‚úÖ T√≠tulos autom√°ticos para conversaciones")
    print("‚úÖ Integraci√≥n con sistema existente")
    print("‚úÖ Fallback a Llama si OpenAI falla")
    print("‚úÖ F√°cil activaci√≥n/desactivaci√≥n")
    
    print("\\nüîß Para integrar:")
    print("1. Agregar este archivo a tu proyecto")
    print("2. Modificar api.py seg√∫n el c√≥digo de integraci√≥n")
    print("3. Configurar OPENAI_API_KEY en tu .env")
    print("4. Usar endpoint /classify para clasificar preguntas")
    
    # Mostrar c√≥digo de integraci√≥n
    print("\\n" + "="*50)
    print("C√ìDIGO DE INTEGRACI√ìN:")
    print("="*50)
    integration_code = integrate_openai_classifier_with_api()
    print(integration_code)